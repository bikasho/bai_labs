{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"colab":{"name":"smoker_detector_base.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"GEOROVbCdXIc","colab_type":"text"},"source":["# Smoker Detector AI application\n","\n","Going forward, AI algorithms will be incorporated into more and more everyday applications. For example, you might want to detect cigarate smoker using a smart AI camera. In this project, we will expolre deep learning to identify a smoker in a video stream. To do this, we first build our base model. We will use a pretrained imageNet model and replace ImageNet last layer with a logistic classifier ( binary classifier ) as our overall application architecture.\n","\n","**Goal** : Design and Build a Deep Learning Model to identify a cigarret smoker in a video stream."]},{"cell_type":"markdown","metadata":{"id":"o8JUvQizdXId","colab_type":"text"},"source":["### Base Model\n","\n","The project (base model) is broken down into multiple steps:\n","\n","* Load and preprocess the videos dataset if required\n","* Build a logistic classifier\n","* Train the classifier on our video dataset\n","* Use the trained classifier to predict\n","\n","![Deep Learning](deep_learn_b.jpg)\n"]},{"cell_type":"markdown","metadata":{"id":"kGwaOc8jdXIe","colab_type":"text"},"source":["**TO DO**\n","\n","1. What input data is required? How you can represent input data i.e videos for imageNet model to consume?\n","\n","2. What should be an ideal video resolution?\n","\n","3. What is the outout?\n","\n","4. What Architecture? ( with respect to the above diagram? )\n","\n","5. What loss function to use for this model?\n"]},{"cell_type":"markdown","metadata":{"id":"XMcsys7PdXIf","colab_type":"text"},"source":["First up is importing the packages you'll need. It's good practice to keep all the imports at the beginning of your code. As you work through this notebook and find you need to import a package, make sure to add the import up here."]},{"cell_type":"code","metadata":{"id":"8SmBKA2-dXIg","colab_type":"code","colab":{}},"source":["# Imports here\n","import torch\n","from torchvision import datasets, transforms\n","import torchvision.models as models\n","from torch import nn\n","from torch import optim\n","from PIL import Image\n","import numpy as np\n","import json\n","\n","\n","%matplotlib inline\n","%config InlineBackend.figure_format = 'retina'\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kf3j7fFldXIm","colab_type":"text"},"source":["## Load the data\n","\n","Here you'll use `torchvision` to load the data ([documentation](http://pytorch.org/docs/0.3.0/torchvision/index.html)). You'll also need to make sure the input data is resized to 224x224??? pixels as required by the pre-trained networks.\n","\n","The validation and testing sets are used to measure the model's performance on data it hasn't seen yet. For this you don't want any scaling or rotation transformations, but you'll need to resize then crop the images to the appropriate size.\n"," "]},{"cell_type":"code","metadata":{"id":"YEtSOJocdXIn","colab_type":"code","colab":{}},"source":["data_dir = 'videos'\n","train_dir = data_dir + '/train'\n","valid_dir = data_dir + '/valid'\n","test_dir = data_dir + '/test'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"T0Js1E8qdXIs","colab_type":"code","colab":{}},"source":["# TODO: Define your transforms for the training, validation, and testing sets\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qWqR9eLCdXIx","colab_type":"text"},"source":["### Label mapping\n","\n"]},{"cell_type":"code","metadata":{"id":"dCADC3t1dXIy","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gQdL0t_idXI3","colab_type":"text"},"source":["# Building and training the classifier\n","\n","Now that the data is ready, it's time to build and train the classifier. As usual, you should use one of the pretrained models from `torchvision.models` to get the image features. Build and train a new feed-forward classifier using those features.\n","\n","Things you'll need to do:\n","\n","* Load a [pre-trained network](http://pytorch.org/docs/master/torchvision/models.html) (If you need a starting point, the VGG networks work great and are straightforward to use)\n","* Define a new, untrained feed-forward network as a classifier ( Logistic Classifier ), using ReLU activations and dropout\n","* Train the classifier layers using backpropagation using the pre-trained network to get the features\n","* Track the loss and accuracy on the validation set to determine the best hyperparameters\n","\n","\n","When training make sure you're updating only the weights of the feed-forward network. You should be able to get the validation accuracy above 70% if you build everything right. Make sure to try different hyperparameters (learning rate, units in the classifier, epochs, etc) to find the best model. Save those hyperparameters to use as default values in the next part of the project.\n"]},{"cell_type":"code","metadata":{"id":"BRBcQWMydXI4","colab_type":"code","colab":{}},"source":["# TODO: Build and train your network\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uyWsES3PdXI9","colab_type":"code","colab":{}},"source":["# Training the model on the training dataset\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ARV6dF6MdXJB","colab_type":"text"},"source":["## Testing your network\n","\n","It's good practice to test your trained network on test data, images/videos the network has never seen either in training or validation. This will give you a good estimate for the model's performance on completely new videos. Run the test videos through the network and measure the accuracy, the same way you did validation. You should be able to reach around 70% accuracy on the test set if the model has been trained well."]},{"cell_type":"code","metadata":{"id":"XlKUfYaBdXJC","colab_type":"code","colab":{}},"source":["# TODO: Do validation on the test set\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GZCYGMTYdXJF","colab_type":"text"},"source":["## Save the checkpoint\n","\n","Now that your network is trained, save the model so you can load it later for making predictions. \n","\n","Remember that you'll want to completely rebuild the model later so you can use it for inference. Make sure to include any information you need in the checkpoint. If you want to load the model and keep training, you'll want to save the number of epochs as well as the optimizer state, `optimizer.state_dict`. You'll likely want to use this trained model in the next part of the project, so best to save it now."]},{"cell_type":"code","metadata":{"id":"JyfP-ZcbdXJG","colab_type":"code","colab":{}},"source":["# TODO: Save the checkpoint "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5VQm4fHvdXJJ","colab_type":"text"},"source":["## Loading the checkpoint\n","\n","At this point it's good to write a function that can load a checkpoint and rebuild the model. That way you can come back to this project and keep working on it without having to retrain the network."]},{"cell_type":"code","metadata":{"id":"ddzd6ycSdXJK","colab_type":"code","colab":{}},"source":["#Loading checkpoint\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bEOebw5VdXJP","colab_type":"text"},"source":["# Inference for classification\n","\n","Now you'll write a function to use a trained network for inference. That is, you'll pass an image into the network and predict the class. Write a function called `predict` that takes an video and a model, \n","\n","First you'll need to handle processing the input image such that it can be used in your network. \n","\n","## Video Preprocessing\n","\n"]},{"cell_type":"code","metadata":{"id":"CQ6MCLZMdXJQ","colab_type":"code","colab":{}},"source":["# TODO: Process a PIL image for use in a PyTorch model\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7VVAR5lMdXJT","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}